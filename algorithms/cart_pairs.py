import numpy as np
import math

from algorithms.cart import Cart
from tree import tree


class CartPairs(Cart):
    def __init__(self, max_depth=None, min_samples_stop=0):
        super().__init__(max_depth, min_samples_stop)

    @staticmethod
    def _set_objects(X, y, a, condition, value):
        """
        Calculate the set of objects in :param X that have a condition in attribute index attribute :param a.
        Condition can be: "eq",  "leq" or "gt" compared to :param value

        Return subsets X, y that satisfies condition
        """
        result_X = []
        result_y = []

        for i in range(len(y)):
            if condition == 'eq' and X[i][a] == value:
                result_X.append(X[i])
                result_y.append(y[i])
            elif condition == 'leq' and X[i][a] <= value:
                result_X.append(X[i])
                result_y.append(y[i])
            elif condition == 'gt' and X[i][a] > value:
                result_X.append(X[i])
                result_y.append(y[i])

        return result_X, result_y

    @staticmethod
    def _number_pairs(y):
        """
        Returns the number of pairs that have different classes
        """
        count = 0
        y_sorted = sorted(y)

        i = 1
        j = 0
        n = len(y)
        while i < n:
            while i < n and y_sorted[i] == y_sorted[i - 1]:
                i += 1
            count += (i - j) * (n - i)
            j = i
            i += 1
        return count

    def _get_best_threshold(self, X, y, a):
        m = y.size  # tirar
        classes_parent = [np.sum(y == c) for c in range(self.n_classes_)]  # tirar
        thresholds, classes_thr = zip(*sorted(zip(X[:, a], y)))
        classes_left = [0] * self.n_classes_
        classes_right = classes_parent.copy()
        pairs_left = 0
        pairs_right = self._number_pairs(y)
        t_best = None
        cost_best = math.inf

        for i in range(1, m):
            node_class = classes_thr[i - 1]
            classes_left[node_class] += 1
            classes_right[node_class] -= 1
            pairs_left += sum([classes_left[j] for j in range(self.n_classes_) if j != node_class])
            pairs_right -= sum([classes_right[j] for j in range(self.n_classes_) if j != node_class])
            if thresholds[i] == thresholds[i - 1]:
                continue
            threshold = (thresholds[i] + thresholds[i - 1]) / 2
            cost = pairs_left / i + pairs_right / (m - i)  # Gini in terms of pairs
            if cost < cost_best:
                cost_best = cost
                t_best = threshold
        return t_best, cost_best

    def _best_split(self, X, y, feature_index_occurrences=None, modified_factor=1):
        """Find the best split for a node.

        "Best" means that the average impurity of the two children, weighted by their
        population, is the smallest possible. Additionally it must be less than the
        impurity of the current node.

        To find the best split, we loop through all the features, and consider all the
        midpoints between adjacent training samples as possible thresholds. We compute
        the Gini impurity of the split generated by that particular feature/threshold
        pair, and return the pair with smallest impurity.

        Returns:
            best_idx: Index of the feature for best split, or None if no split is found.
            best_thr: Threshold to use for the split, or None if no split is found.
        """
        # Need at least two elements to split a node.
        m = y.size
        if m <= 1:
            return None, None

        # Best cost (Gini in terms of pairs)
        best_cost = math.inf

        best_idx, best_thr = None, None

        # Loop through all features.
        for idx in range(self.n_features_):
            t_best_a, cost_best_a = self._get_best_threshold(X, y, idx)
            if cost_best_a < best_cost:
                best_cost = cost_best_a
                best_idx = idx
                best_thr = t_best_a

        return best_idx, best_thr

    def _grow_tree(self, X, y, depth=0, feature_index_occurrences=None, modified_factor=1, calculate_gini=True):
        """Build a decision tree by recursively finding the best split."""
        # Population for each class in current node. The predicted class is the one with
        # largest population.
        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]
        predicted_class = np.argmax(num_samples_per_class)
        node = tree.Node(
            num_samples=y.size,
            num_samples_per_class=num_samples_per_class,
            predicted_class=predicted_class,
            feature_index_occurrences=feature_index_occurrences.copy()
        )
        if calculate_gini:
            node.gini = self._gini(y)

        # Split recursively until maximum depth is reached.
        if depth < self.max_depth and node.num_samples >= self.min_samples_stop:
            idx, thr = self._best_split(X, y, feature_index_occurrences=feature_index_occurrences,
                                        modified_factor=modified_factor)
            if idx is not None:
                indices_left = X[:, idx] < thr
                X_left, y_left = X[indices_left], y[indices_left]
                X_right, y_right = X[~indices_left], y[~indices_left]
                node.feature_index = idx
                node.threshold = thr
                node.feature_index_occurrences[idx] += 1
                node.left = self._grow_tree(X_left, y_left, depth + 1,
                                            feature_index_occurrences=node.feature_index_occurrences.copy(),
                                            modified_factor=modified_factor, calculate_gini=calculate_gini)
                node.right = self._grow_tree(X_right, y_right, depth + 1,
                                             feature_index_occurrences=node.feature_index_occurrences.copy(),
                                             modified_factor=modified_factor, calculate_gini=calculate_gini)
        return node
